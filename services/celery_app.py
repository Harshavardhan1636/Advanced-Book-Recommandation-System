"""
Celery configuration for background tasks
Handles heavy computations asynchronously
"""

from celery import Celery
import os
import logging

logger = logging.getLogger(__name__)

# Celery configuration
REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379/0")
CELERY_BROKER_URL = os.getenv("CELERY_BROKER_URL", REDIS_URL)
CELERY_RESULT_BACKEND = os.getenv("CELERY_RESULT_BACKEND", REDIS_URL)

# Create Celery app
celery_app = Celery(
    'book_recommendation',
    broker=CELERY_BROKER_URL,
    backend=CELERY_RESULT_BACKEND
)

# Celery configuration
celery_app.conf.update(
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    timezone='UTC',
    enable_utc=True,
    task_track_started=True,
    task_time_limit=30 * 60,  # 30 minutes
    task_soft_time_limit=25 * 60,  # 25 minutes
)

logger.info("âœ… Celery app configured")


# Background tasks

@celery_app.task(name='generate_recommendations')
def generate_recommendations_task(book_id: str, user_id: int, limit: int = 10):
    """
    Generate ML recommendations in background
    
    Args:
        book_id: Target book ID
        user_id: User ID
        limit: Number of recommendations
    """
    from services.recommendation_engine import RecommendationEngine
    from database import get_db
    
    logger.info(f"Generating recommendations for book {book_id}, user {user_id}")
    
    try:
        engine = RecommendationEngine(strategy="hybrid")
        # This would fetch book and generate recommendations
        # Implementation depends on your specific needs
        
        return {
            "status": "success",
            "book_id": book_id,
            "user_id": user_id,
            "recommendations": []  # Placeholder
        }
    except Exception as e:
        logger.error(f"Recommendation generation failed: {e}")
        return {
            "status": "error",
            "error": str(e)
        }


@celery_app.task(name='update_book_embeddings')
def update_book_embeddings_task(book_ids: list):
    """
    Update book embeddings for similarity search
    
    Args:
        book_ids: List of book IDs to update
    """
    logger.info(f"Updating embeddings for {len(book_ids)} books")
    
    try:
        # This would use Sentence-BERT to generate embeddings
        # Implementation depends on your specific needs
        
        return {
            "status": "success",
            "updated": len(book_ids)
        }
    except Exception as e:
        logger.error(f"Embedding update failed: {e}")
        return {
            "status": "error",
            "error": str(e)
        }


@celery_app.task(name='generate_year_review')
def generate_year_review_task(user_id: int, year: int):
    """
    Generate comprehensive year-in-review report
    
    Args:
        user_id: User ID
        year: Year to review
    """
    logger.info(f"Generating year review for user {user_id}, year {year}")
    
    try:
        from database import get_db
        from database.models import User, ReadingHistoryDB
        from datetime import datetime
        
        # This would generate comprehensive analytics
        # Implementation depends on your specific needs
        
        return {
            "status": "success",
            "user_id": user_id,
            "year": year,
            "report": {}  # Placeholder
        }
    except Exception as e:
        logger.error(f"Year review generation failed: {e}")
        return {
            "status": "error",
            "error": str(e)
        }


@celery_app.task(name='sync_external_apis')
def sync_external_apis_task():
    """
    Sync data from external APIs (trending books, bestsellers, etc.)
    Runs periodically
    """
    logger.info("Syncing data from external APIs")
    
    try:
        from services.api_providers import APIProviderFactory
        
        # This would fetch and cache trending books
        # Implementation depends on your specific needs
        
        return {
            "status": "success",
            "synced_at": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"API sync failed: {e}")
        return {
            "status": "error",
            "error": str(e)
        }


@celery_app.task(name='cleanup_old_cache')
def cleanup_old_cache_task():
    """
    Clean up old cache entries
    Runs periodically
    """
    logger.info("Cleaning up old cache entries")
    
    try:
        from services.cache import cache
        
        # This would clean up expired cache entries
        # Redis handles TTL automatically, but this can do additional cleanup
        
        return {
            "status": "success",
            "cleaned_at": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Cache cleanup failed: {e}")
        return {
            "status": "error",
            "error": str(e)
        }


# Periodic tasks configuration
celery_app.conf.beat_schedule = {
    'sync-external-apis-every-hour': {
        'task': 'sync_external_apis',
        'schedule': 3600.0,  # Every hour
    },
    'cleanup-cache-daily': {
        'task': 'cleanup_old_cache',
        'schedule': 86400.0,  # Every day
    },
}
